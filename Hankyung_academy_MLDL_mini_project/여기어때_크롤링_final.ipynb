{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20264/3659261508.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 호텔 예약 주소 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서울 호텔 검색 페이지 - 지역별\n",
    "seoul_hotel = [\n",
    "    'https://www.goodchoice.kr/product/search/2/2012',\n",
    "    'https://www.goodchoice.kr/product/search/2/2019',\n",
    "    'https://www.goodchoice.kr/product/search/2/2016',\n",
    "    'https://www.goodchoice.kr/product/search/2/2014',\n",
    "    'https://www.goodchoice.kr/product/search/2/2015',\n",
    "    'https://www.goodchoice.kr/product/search/2/2020',\n",
    "    'https://www.goodchoice.kr/product/search/2/2018',\n",
    "    'https://www.goodchoice.kr/product/search/2/2017',\n",
    "    'https://www.goodchoice.kr/product/search/2/2021'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "\n",
    "for link in link_list:\n",
    "    a = link.split('&')[0]\n",
    "    df.append(a)\n",
    "\n",
    "linklist = pd.DataFrame({\n",
    "    'hotel_link' : df\n",
    "})\n",
    "\n",
    "linklist.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linklist.to_csv('hotel_linklist.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.goodchoice.kr/product/detail?ano=6490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.goodchoice.kr/product/detail?ano=1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.goodchoice.kr/product/detail?ano=6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.goodchoice.kr/product/detail?ano=6258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.goodchoice.kr/product/detail?ano=4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          hotel_link\n",
       "0  https://www.goodchoice.kr/product/detail?ano=6490\n",
       "1  https://www.goodchoice.kr/product/detail?ano=1...\n",
       "2  https://www.goodchoice.kr/product/detail?ano=6...\n",
       "3  https://www.goodchoice.kr/product/detail?ano=6258\n",
       "4  https://www.goodchoice.kr/product/detail?ano=4..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_link = pd.read_csv('data/hotel_linklist.csv',index_col=False)\n",
    "hotel_link.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hotel_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 크롤링 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 결과 담을 리스트\n",
    "\n",
    "# 크롤링 함수\n",
    "def crawl(start, end):\n",
    "    for p in range(start,end):\n",
    "        html = driver.page_source\n",
    "        soup = bs(html, 'html.parser')\n",
    "        \n",
    "        reviews = soup.select('#review > ul > li')\n",
    "        hotel_name = driver.find_element_by_css_selector(\"#content > div.top > div.right > div.info > h2\").text\n",
    "        \n",
    "        for r in reviews:\n",
    "            review.append(r.select_one('.txt').text)\n",
    "            star.append(r.select_one('.score_wrap_sm .num').text)\n",
    "            name.append(hotel_name)\n",
    "        \n",
    "        try : \n",
    "            driver.find_element_by_xpath('//*[@id=\"pagination\"]/div/button['+str(p)+']').click()\n",
    "        except : \n",
    "            pass\n",
    "        time.sleep(2)\n",
    "        #print(soup.select('.paging .on')[0].text)\n",
    "\n",
    "def make_review_crawl(url):\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    # 페이지 파싱\n",
    "    html = driver.page_source\n",
    "    soup = bs(html, 'html.parser')\n",
    "\n",
    "    # '리뷰' 클릭하도록 명령\n",
    "    driver.find_element_by_xpath('//*[@id=\"content\"]/div[2]/button[3]').click()\n",
    "    \n",
    "    top_text = soup.select('.score_top')[0].find('strong').text\n",
    "    top_score = soup.select('.score_top .num')[0].text\n",
    "    top_total=soup.select('.score_top')[0].find('p').find('b').text\n",
    "\n",
    "    # 리뷰 총 개수\n",
    "    top_total = int(soup.select('.score_top')[0].find('p').find('b').text)\n",
    "\n",
    "    # 마지막 페이지 수 (한페이지에 리뷰 10개씩)\n",
    "    if top_total % 10 == 0 :\n",
    "        last_page = top_total // 10\n",
    "    else : \n",
    "        last_page = top_total // 10  + 1\n",
    "\n",
    "    # next_page 몇 번 클릭 해야하는지 설정\n",
    "    if last_page % 5 == 0:\n",
    "        page_step = last_page // 5 \n",
    "    else:\n",
    "        page_step = last_page // 5 + 1   \n",
    "    \n",
    "    print(top_total, last_page, page_step)\n",
    "    step = 1\n",
    "    while(page_step >= step):\n",
    "        \n",
    "        # 첫번째 step\n",
    "        if step == 1:\n",
    "            print('step1 loop')\n",
    "            crawl(2,7)\n",
    "            \n",
    "        # 마지막 step\n",
    "        elif step == page_step:\n",
    "            print('step 마지막 loop')\n",
    "\n",
    "                \n",
    "            if top_total % 50 > 10:\n",
    "                            \n",
    "                if last_page % 5 == 0:\n",
    "                    end_page = 7\n",
    "                else: \n",
    "                    end_page =last_page % 5 + 2\n",
    "                \n",
    "                crawl(3, end_page)\n",
    "\n",
    "            # 마지막 페이지\n",
    "            html = driver.page_source\n",
    "            soup = bs(html, 'html.parser')\n",
    "            reviews = soup.select('#review > ul > li')\n",
    "            hotel_name = driver.find_element_by_css_selector(\"#content > div.top > div.right > div.info > h2\").text\n",
    "        \n",
    "            for r in reviews:\n",
    "                review.append(r.select_one('.txt').text)\n",
    "                star.append(r.select_one('.score_wrap_sm .num').text)\n",
    "                name.append(hotel_name)    \n",
    "        # 중간 step\n",
    "        else:\n",
    "            #print('step 중간 loop')\n",
    "            crawl(3,8)\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 리뷰 크롤링  \n",
    "- 예외 발생 시 링크를 retry_link 에 저장  \n",
    "- 10개가 끝날 때 마다 df 데이터 프레임 만들어서 csv에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1917 192 39\n",
      "step1 loop\n"
     ]
    }
   ],
   "source": [
    "review = []\n",
    "name = []\n",
    "star = []\n",
    "retry_link = []\n",
    "\n",
    "driver = webdriver.Chrome('./chromedriver')\n",
    "\n",
    "#0에서 100 까지 다시 해야함 ㅠㅠ\n",
    "\n",
    "for i in range(241,len(hotel_link)+1):\n",
    "    a = hotel_link.iloc[i]['hotel_link']\n",
    "    driver.implicitly_wait(3)\n",
    "    try : \n",
    "        make_review_crawl(a)\n",
    "        print(f'241부터 {i}번째 호텔 끝')\n",
    "    except : \n",
    "        retry_link.append(a)\n",
    "        print(f'{i}번째 호텔 못 끝냄')\n",
    "    if i % 10 == 0:\n",
    "        df = pd.DataFrame({\n",
    "            '호텔명' : name,\n",
    "            '리뷰' : review,\n",
    "            '별점' : star\n",
    "        })\n",
    "        df.to_csv(f'hotel_review_241부터_{i}th.csv',index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}